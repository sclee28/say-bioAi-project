{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd5bea1",
   "metadata": {},
   "source": [
    "# 1.손실 함수 및 메트릭 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86011eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 개선된 손실 함수 및 메트릭 시스템\n",
    "class AdaptiveBraTSLoss(nn.Module):\n",
    "    \"\"\"적응형 BraTS 손실 함수 (클래스 불균형 고려)\"\"\"\n",
    "    \n",
    "    def __init__(self, ce_weight=1.0, dice_weight=1.0, focal_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "        \n",
    "        # 클래스 가중치\n",
    "        self.class_weights = torch.tensor([0.1, 2.0, 1.5, 2.5]).to(device)\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        print(\"📊 적응형 손실 함수 초기화 (CE + Dice + Focal)\")\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Cross-Entropy Loss\n",
    "        ce_loss = self.ce_loss(predictions, targets)\n",
    "        \n",
    "        # Multi-Class Dice Loss\n",
    "        dice_loss = self._multiclass_dice_loss(predictions, targets)\n",
    "        \n",
    "        # Focal Loss\n",
    "        focal_loss = self._focal_loss(predictions, targets)\n",
    "        \n",
    "        # 총 손실\n",
    "        total_loss = (self.ce_weight * ce_loss +\n",
    "                     self.dice_weight * dice_loss +\n",
    "                     self.focal_weight * focal_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def _multiclass_dice_loss(self, predictions, targets):\n",
    "        \"\"\"다중 클래스 Dice 손실\"\"\"\n",
    "        smooth = 1e-6\n",
    "        probs = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        # 원-핫 인코딩\n",
    "        targets_one_hot = F.one_hot(targets.long(), num_classes=predictions.shape[1])\n",
    "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        dice_scores = []\n",
    "        for i in range(predictions.shape[1]):\n",
    "            pred_i = probs[:, i]\n",
    "            target_i = targets_one_hot[:, i]\n",
    "            \n",
    "            intersection = (pred_i * target_i).sum()\n",
    "            union = pred_i.sum() + target_i.sum()\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            \n",
    "            class_weight = self.class_weights[i] if i < len(self.class_weights) else 1.0\n",
    "            dice_scores.append(dice * class_weight)\n",
    "        \n",
    "        return 1.0 - torch.stack(dice_scores).mean()\n",
    "    \n",
    "    def _focal_loss(self, predictions, targets, alpha=0.25, gamma=2.0):\n",
    "        \"\"\"Focal Loss\"\"\"\n",
    "        ce_loss = F.cross_entropy(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# 손실 함수 초기화\n",
    "criterion = AdaptiveBraTSLoss(ce_weight=1.0, dice_weight=2.0, focal_weight=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f5aa6",
   "metadata": {},
   "source": [
    "# 2. 성능 메트릭 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveMetrics:\n",
    "    \"\"\"포괄적 성능 메트릭\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=4):\n",
    "        self.num_classes = num_classes\n",
    "        self.reset()\n",
    "        self.class_names = ['Background', 'NCR/NET', 'ED', 'ET']\n",
    "        print(\"📏 포괄적 메트릭 시스템 초기화\")\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"메트릭 초기화\"\"\"\n",
    "        self.all_predictions = []\n",
    "        self.all_targets = []\n",
    "        self.dice_scores = []\n",
    "        self.iou_scores = []\n",
    "        self.processing_times = []\n",
    "    \n",
    "    def update(self, predictions, targets, processing_time=None):\n",
    "        \"\"\"메트릭 업데이트\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if predictions.dim() == 5:  # (B, C, H, W, D)\n",
    "                probs = F.softmax(predictions, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "            else:\n",
    "                preds = predictions\n",
    "            \n",
    "            # CPU로 이동하여 저장\n",
    "            preds_np = preds.cpu().numpy().flatten()\n",
    "            targets_np = targets.cpu().numpy().flatten()\n",
    "            \n",
    "            self.all_predictions.extend(preds_np)\n",
    "            self.all_targets.extend(targets_np)\n",
    "            \n",
    "            # 배치별 Dice 및 IoU 계산\n",
    "            batch_dice = self._calculate_batch_dice(preds, targets)\n",
    "            batch_iou = self._calculate_batch_iou(preds, targets)\n",
    "            \n",
    "            self.dice_scores.extend(batch_dice)\n",
    "            self.iou_scores.extend(batch_iou)\n",
    "            \n",
    "            if processing_time:\n",
    "                self.processing_times.append(processing_time)\n",
    "    \n",
    "    def _calculate_batch_dice(self, preds, targets):\n",
    "        \"\"\"배치별 Dice 점수 계산\"\"\"\n",
    "        batch_dice = []\n",
    "        batch_size = preds.shape[0]\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            pred_b = preds[b]\n",
    "            target_b = targets[b]\n",
    "            dice_per_class = []\n",
    "            \n",
    "            for class_id in range(1, self.num_classes):  # 배경 제외\n",
    "                pred_mask = (pred_b == class_id).float()\n",
    "                target_mask = (target_b == class_id).float()\n",
    "                \n",
    "                intersection = (pred_mask * target_mask).sum()\n",
    "                union = pred_mask.sum() + target_mask.sum()\n",
    "                \n",
    "                if union > 0:\n",
    "                    dice = (2.0 * intersection / union).item()\n",
    "                else:\n",
    "                    dice = 1.0 if intersection == 0 else 0.0\n",
    "                \n",
    "                dice_per_class.append(dice)\n",
    "            \n",
    "            batch_dice.append(np.mean(dice_per_class))\n",
    "        \n",
    "        return batch_dice\n",
    "    \n",
    "    def get_comprehensive_results(self):\n",
    "        \"\"\"포괄적 결과 반환\"\"\"\n",
    "        if not self.all_predictions or not self.all_targets:\n",
    "            return {'error': '계산할 데이터가 없습니다.'}\n",
    "        \n",
    "        # 기본 분류 메트릭\n",
    "        accuracy = accuracy_score(self.all_targets, self.all_predictions)\n",
    "        precision = precision_score(self.all_targets, self.all_predictions,\n",
    "                                   average='weighted', zero_division=0)\n",
    "        recall = recall_score(self.all_targets, self.all_predictions,\n",
    "                             average='weighted', zero_division=0)\n",
    "        f1 = f1_score(self.all_targets, self.all_predictions,\n",
    "                      average='weighted', zero_division=0)\n",
    "        \n",
    "        # 분할 메트릭\n",
    "        mean_dice = np.mean(self.dice_scores) if self.dice_scores else 0.0\n",
    "        mean_iou = np.mean(self.iou_scores) if self.iou_scores else 0.0\n",
    "        \n",
    "        # 처리 시간\n",
    "        avg_processing_time = np.mean(self.processing_times) if self.processing_times else 0.0\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'dice_score': mean_dice,\n",
    "            'iou_score': mean_iou,\n",
    "            'processing_time': avg_processing_time,\n",
    "            'total_samples': len(self.all_predictions)\n",
    "        }\n",
    "\n",
    "# 메트릭 초기화\n",
    "metrics = ComprehensiveMetrics(num_classes=config.num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4528100",
   "metadata": {},
   "source": [
    "# 3. 훈련 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b75873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 훈련 시스템\n",
    "class Trainer:\n",
    "    \"\"\"지능형 훈련 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        \n",
    "        # 옵티마이저\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=config.weight_decay,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # 스케줄러\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer,\n",
    "            T_0=5,\n",
    "            T_mult=2,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # 손실 함수\n",
    "        self.criterion = AdaptiveBraTSLoss()\n",
    "        \n",
    "        # 성능 추적\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_dice': [], 'val_dice': [],\n",
    "            'learning_rate': [], 'epoch_time': []\n",
    "        }\n",
    "        \n",
    "        self.best_dice = 0.0\n",
    "        self.best_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.early_stop_patience = 8\n",
    "        \n",
    "        print(\"🚀 스마트 훈련 시스템 초기화\")\n",
    "        print(f\" └── 옵티마이저: AdamW (lr={config.learning_rate})\")\n",
    "        print(f\" └── 스케줄러: CosineAnnealingWarmRestarts\")\n",
    "        print(f\" └── 조기 종료: patience={self.early_stop_patience}\")\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"훈련 에포크\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        train_metrics = ComprehensiveMetrics(self.config.num_classes)\n",
    "        processed_batches = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f\"훈련 Epoch {epoch}\")\n",
    "        \n",
    "        for batch_idx, (volumes, targets) in enumerate(pbar):\n",
    "            try:\n",
    "                volumes = volumes.to(self.config.device, non_blocking=True)\n",
    "                targets = targets.to(self.config.device, non_blocking=True)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                batch_start_time = time.time()\n",
    "                outputs = self.model(volumes)\n",
    "                processing_time = time.time() - batch_start_time\n",
    "                \n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"⚠️ 배치 {batch_idx}: NaN/Inf 손실 감지, 스킵\")\n",
    "                    continue\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.model.parameters(),\n",
    "                    max_norm=self.config.gradient_clip_norm\n",
    "                )\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                train_metrics.update(outputs, targets, processing_time)\n",
    "                processed_batches += 1\n",
    "                \n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'LR': f'{current_lr:.2e}'\n",
    "                })\n",
    "                \n",
    "                if batch_idx % 3 == 0:\n",
    "                    self._cleanup_memory()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 배치 {batch_idx} 훈련 실패: {e}\")\n",
    "                continue\n",
    "        \n",
    "        avg_loss = running_loss / max(processed_batches, 1)\n",
    "        train_results = train_metrics.get_comprehensive_results()\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        return avg_loss, train_results['dice_score'], epoch_time\n",
    "    \n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"검증 에포크\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        val_metrics = ComprehensiveMetrics(self.config.num_classes)\n",
    "        processed_batches = 0\n",
    "        \n",
    "        pbar = tqdm(self.val_loader, desc=f\"검증 Epoch {epoch}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (volumes, targets) in enumerate(pbar):\n",
    "                try:\n",
    "                    volumes = volumes.to(self.config.device, non_blocking=True)\n",
    "                    targets = targets.to(self.config.device, non_blocking=True)\n",
    "                    \n",
    "                    batch_start_time = time.time()\n",
    "                    outputs = self.model(volumes)\n",
    "                    processing_time = time.time() - batch_start_time\n",
    "                    \n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                    \n",
    "                    if not (torch.isnan(loss) or torch.isinf(loss)):\n",
    "                        running_loss += loss.item()\n",
    "                        val_metrics.update(outputs, targets, processing_time)\n",
    "                        processed_batches += 1\n",
    "                        \n",
    "                    pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        avg_loss = running_loss / max(processed_batches, 1)\n",
    "        val_results = val_metrics.get_comprehensive_results()\n",
    "        \n",
    "        return avg_loss, val_results['dice_score'], val_results\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        \"\"\"전체 훈련 프로세스\"\"\"\n",
    "        print(f\"🎯 훈련 시작: {num_epochs} 에포크\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\n📅 Epoch {epoch}/{num_epochs}\")\n",
    "            \n",
    "            # 훈련\n",
    "            train_loss, train_dice, epoch_time = self.train_epoch(epoch)\n",
    "            \n",
    "            # 검증\n",
    "            val_loss, val_dice, val_results = self.validate_epoch(epoch)\n",
    "            \n",
    "            # 스케줄러 업데이트\n",
    "            self.scheduler.step()\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # 히스토리 업데이트\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['train_dice'].append(train_dice)\n",
    "            self.history['val_dice'].append(val_dice)\n",
    "            self.history['learning_rate'].append(current_lr)\n",
    "            self.history['epoch_time'].append(epoch_time)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"훈련 - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}\")\n",
    "            print(f\"검증 - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}\")\n",
    "            print(f\"학습률: {current_lr:.2e}, 시간: {epoch_time:.1f}초\")\n",
    "            \n",
    "            # 베스트 모델 체크\n",
    "            is_best = val_dice > self.best_dice\n",
    "            if is_best:\n",
    "                self.best_dice = val_dice\n",
    "                self.patience_counter = 0\n",
    "                self.save_checkpoint(epoch, is_best=True)\n",
    "                print(f\"🏆 새로운 최고 성능: Dice {val_dice:.4f}\")\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # 조기 종료 체크\n",
    "            if self.patience_counter >= self.early_stop_patience:\n",
    "                print(f\"⏹️ 조기 종료: {self.early_stop_patience} 에포크 개선 없음\")\n",
    "                break\n",
    "            \n",
    "            # 정기 메모리 정리\n",
    "            if epoch % self.config.memory_cleanup_interval == 0:\n",
    "                self._cleanup_memory(full_cleanup=True)\n",
    "                print(\"🧹 전체 메모리 정리 수행\")\n",
    "        \n",
    "        print(f\"\\n🎉 훈련 완료! 최고 Dice: {self.best_dice:.4f}\")\n",
    "        return self.history\n",
    "    \n",
    "    def save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"체크포인트 저장\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_dice': self.best_dice,\n",
    "            'history': self.history,\n",
    "            'config_dict': {\n",
    "                'in_channels': self.config.in_channels,\n",
    "                'num_classes': self.config.num_classes,\n",
    "                'base_features': self.config.base_features,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        filename = \"best_model.pth\" if is_best else f\"checkpoint_epoch_{epoch}.pth\"\n",
    "        filepath = os.path.join(self.config.model_save_path, filename)\n",
    "        torch.save(checkpoint, filepath)\n",
    "        \n",
    "        if is_best:\n",
    "            print(f\"💾 최고 성능 모델 저장: {filepath}\")\n",
    "    \n",
    "    def _cleanup_memory(self, full_cleanup=False):\n",
    "        \"\"\"메모리 정리\"\"\"\n",
    "        if self.config.device.type == 'mps':\n",
    "            torch.mps.empty_cache()\n",
    "        elif torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        if full_cleanup:\n",
    "            gc.collect()\n",
    "\n",
    "# 훈련자 생성\n",
    "trainer = SmartTrainer(model, train_loader, val_loader, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149d57f",
   "metadata": {},
   "source": [
    "# 4. 훈련 실행 및 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4769500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 모델 훈련 실행\n",
    "def monitor_memory():\n",
    "    \"\"\"메모리 사용량 모니터링\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            allocated = torch.mps.current_allocated_memory() / 1024**2\n",
    "            reserved = torch.mps.driver_allocated_memory() / 1024**2\n",
    "            print(f\"💾 MPS 메모리 - 할당: {allocated:.1f}MB, 예약: {reserved:.1f}MB\")\n",
    "        except:\n",
    "            print(\"💾 MPS 메모리 정보 조회 실패\")\n",
    "    else:\n",
    "        print(\"💾 MPS 메모리 모니터링 불가\")\n",
    "\n",
    "def visualize_training_results(history):\n",
    "    \"\"\"훈련 결과 시각화\"\"\"\n",
    "    if not history['train_loss']:\n",
    "        print(\"⚠️ 훈련 히스토리가 비어있습니다.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('📊 훈련 결과 분석', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # 1. 손실 함수 변화\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='훈련 Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='검증 Loss', linewidth=2)\n",
    "    ax1.set_title('손실 함수 변화')\n",
    "    ax1.set_xlabel('에포크')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Dice 점수 변화\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(epochs, history['train_dice'], 'g-', label='훈련 Dice', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_dice'], 'orange', label='검증 Dice', linewidth=2)\n",
    "    ax2.set_title('Dice 점수 변화')\n",
    "    ax2.set_xlabel('에포크')\n",
    "    ax2.set_ylabel('Dice Score')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    # 3. 학습률 변화\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.semilogy(epochs, history['learning_rate'], 'purple', linewidth=2)\n",
    "    ax3.set_title('학습률 변화')\n",
    "    ax3.set_xlabel('에포크')\n",
    "    ax3.set_ylabel('Learning Rate (log scale)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 에포크별 시간\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.bar(epochs, history['epoch_time'], color='skyblue', alpha=0.7)\n",
    "    ax4.set_title('에포크별 훈련 시간')\n",
    "    ax4.set_xlabel('에포크')\n",
    "    ax4.set_ylabel('시간 (초)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"🚀 BraTS 2021 개선 버전 훈련 시작!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 초기 메모리 상태\n",
    "monitor_memory()\n",
    "\n",
    "try:\n",
    "    # 모델 테스트\n",
    "    print(\"🧪 모델 구조 테스트...\")\n",
    "    test_volume = torch.randn(1, 4, 64, 64, 64).to(config.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_output = model(test_volume)\n",
    "    \n",
    "    print(f\" ✅ 테스트 성공: {test_volume.shape} → {test_output.shape}\")\n",
    "    del test_volume, test_output\n",
    "    \n",
    "    if config.device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    # 실제 훈련 실행\n",
    "    print(f\"\\n🎯 훈련 시작 ({config.epochs} 에포크)\")\n",
    "    history = trainer.train(num_epochs=config.epochs)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    print(f\"\\n📊 훈련 결과 시각화\")\n",
    "    visualize_training_results(history)\n",
    "    \n",
    "    # 최종 결과 요약\n",
    "    print(f\"\\n🎉 훈련 완료!\")\n",
    "    print(f\" 🏆 최고 Dice 점수: {trainer.best_dice:.4f}\")\n",
    "    \n",
    "    if history['train_loss']:\n",
    "        print(f\" 📉 최종 훈련 Loss: {history['train_loss'][-1]:.4f}\")\n",
    "        print(f\" 📉 최종 검증 Loss: {history['val_loss'][-1]:.4f}\")\n",
    "        print(f\" 📈 최종 검증 Dice: {history['val_dice'][-1]:.4f}\")\n",
    "        print(f\" ⏱️ 총 훈련 시간: {sum(history['epoch_time']):.1f}초\")\n",
    "        print(f\" ⚡ 평균 에포크 시간: {np.mean(history['epoch_time']):.1f}초\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 훈련 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # 메모리 정리\n",
    "    trainer._cleanup_memory(full_cleanup=True)\n",
    "    monitor_memory()\n",
    "    print(\"🧹 메모리 정리 완료\")\n",
    "\n",
    "print(f\"\\n🏁 모든 작업 완료: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
